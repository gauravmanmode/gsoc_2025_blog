<!DOCTYPE html>
<html  data-accent-color="violet" data-content_root="">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>GSoC 2025 with Optimagic: Adding More Optimizer Interfaces to Optimagic - GSoC 2025 Blog</title><link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/shibuya.css" />
    <link media="print" rel="stylesheet" type="text/css" href="_static/print.css" />
    <link rel="stylesheet" type="text/css" href="_static/a.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="GSoC 2025 with Optimagic: Adding More Optimizer Interfaces to Optimagic"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="report.html">
      
      
      <strong>GSoC 2025 Blog</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2 -translate-x-2"></span>
          <span class="hamburger_3 -translate-x-1"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0">
        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div class="localtoc"><h3>On this page</h3><ul>
<li><a class="reference internal" href="#">GSoC 2025 with Optimagic: Adding More Optimizer Interfaces to Optimagic</a></li>
<li><a class="reference internal" href="#intro">Intro üìù</a><ul>
<li><a class="reference internal" href="#motivation">Motivation</a></li>
<li><a class="reference internal" href="#why-optimization-needs-a-little-magic">Why Optimization Needs a Little Magic</a></li>
</ul>
</li>
<li><a class="reference internal" href="#optimagic-a-unified-interface-to-optimizers">ü™Ñ Optimagic: A Unified Interface to Optimizers</a><ul>
<li><a class="reference internal" href="#flexibility-at-its-core">Flexibility at its core.</a></li>
<li><a class="reference internal" href="#consistency-is-the-key">Consistency is the key</a></li>
</ul>
</li>
<li><a class="reference internal" href="#code-contributions">Code Contributions üíª</a><ul>
<li><a class="reference internal" href="#optimizers-from-nevergrad-merged">Optimizers from Nevergrad (Merged)</a><ul>
<li><a class="reference internal" href="#why-nevergrad">Why Nevergrad?</a></li>
<li><a class="reference internal" href="#example-usage">Example usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#adding-needs-bounds-and-supports-infinite-bounds-fields-in-the-algoinfo-merged">Adding <code class="docutils literal notranslate"><span class="pre">needs_bounds</span></code> and <code class="docutils literal notranslate"><span class="pre">supports_infinite_bounds</span></code> fields in the AlgoInfo (Merged)</a></li>
<li><a class="reference internal" href="#migrate-nevergrad-optimizers-to-new-documentation-style-open">Migrate Nevergrad optimizers to new documentation style (Open)</a></li>
<li><a class="reference internal" href="#wrap-local-optimizers-from-gradient-free-optimizers-open">Wrap Local Optimizers from Gradient-Free Optimizers (Open)</a></li>
<li><a class="reference internal" href="#wrap-population-based-optimizers-from-gradient-free-optimizers-open">Wrap Population-Based Optimizers from Gradient-Free Optimizers (Open)</a><ul>
<li><a class="reference internal" href="#rework-test-many-algorithms">Rework <code class="docutils literal notranslate"><span class="pre">test_many_algorithms</span></code></a></li>
<li><a class="reference internal" href="#new-example-in-class-sphereexampleinternaloptimizationproblemwithconverter">New Example in class SphereExampleInternalOptimizationProblemWithConverter</a></li>
</ul>
</li>
<li><a class="reference internal" href="#add-l-bfgs-optimizer-from-pyensmallen-open">Add L-BFGS optimizer from pyensmallen (Open)</a></li>
<li><a class="reference internal" href="#issues-raised-by-me">Issues raised by me:</a></li>
<li><a class="reference internal" href="#what-does-this-mean">What does this mean</a></li>
<li><a class="reference internal" href="#future-work">Future Work</a><ul>
<li><a class="reference internal" href="#wrap-grid-search-and-smbo-based-optimizers-from-gradient-free-optimizers">Wrap Grid Search and SMBO-Based Optimizers from Gradient-Free Optimizers</a></li>
<li><a class="reference internal" href="#maintenance">Maintenance üõ†Ô∏è</a></li>
</ul>
</li>
<li><a class="reference internal" href="#acknowledgements">Acknowledgements</a></li>
</ul>
</li>
</ul>
</div><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="report.html"><span itemprop="name">GSoC 2025 Blog</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">GSoC 2025 with Optimagic: Adding More Optimizer Interfaces to Optimagic</strong>
        <meta itemprop="position" content="2" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <section class="tex2jax_ignore mathjax_ignore" id="gsoc-2025-with-optimagic-adding-more-optimizer-interfaces-to-optimagic">
<h1>GSoC 2025 with Optimagic: Adding More Optimizer Interfaces to Optimagic<a class="headerlink" href="#gsoc-2025-with-optimagic-adding-more-optimizer-interfaces-to-optimagic" title="Permalink to this headline">¬∂</a></h1>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="intro">
<h1>Intro üìù<a class="headerlink" href="#intro" title="Permalink to this headline">¬∂</a></h1>
<p>This is my final report and blog post for my Google Summer of Code 2025 project, titled <a class="reference external" href="https://summerofcode.withgoogle.com/programs/2025/projects/j9i3Vx5T">‚ÄòAdding More Optimizer Interfaces to Optimagic‚Äô</a>, under the <a class="reference external" href="https://numfocus.org/">NumFOCUS</a> organization, working on the <a class="reference external" href="https://estimagic.org/">Optimagic Project</a>, supported by NumFOCUS.</p>
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¬∂</a></h2>
<p>I am a graduate student in Mathematics. I love topology, and also worked on numerical methods during my dissertation. Working with optimagic gave me the perfect opportunity to dive into optimization techniques. While my coursework covered boring topics, working on Optimagic introduced me to state-of-the-art algorithms used in real-world applications.</p>
</section>
<section id="why-optimization-needs-a-little-magic">
<h2>Why Optimization Needs a Little Magic<a class="headerlink" href="#why-optimization-needs-a-little-magic" title="Permalink to this headline">¬∂</a></h2>
<p>Optimization is challenging because real-world problems are complex. Functions can be non-linear, non-differentiable, or have multiple optima, making it tough to pinpoint the best solution. For instance, in machine learning, black-box functions where only inputs and outputs are known can be noisy, high-dimensional, or feature steep valleys and flat plateaus, which challenge most algorithms. Some problems require finding global optima, while others need local solutions, and choosing the wrong algorithm can lead to poor results. No single algorithm solves every optimization problem. Depending on the problem‚Äôs characteristics, one algorithm may outperform another.</p>
<p>Moreover, switching between algorithms often involves rewriting code between libraries, which is frustrating for researchers and developers focused on solving their problems.</p>
<p>Optimagic addresses these challenges by offering a unified interface for a wide range of optimizers, from gradient-based to derivative-free. Users can switch algorithms seamlessly without modifying their code.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="optimagic-a-unified-interface-to-optimizers">
<h1>ü™Ñ Optimagic: A Unified Interface to Optimizers<a class="headerlink" href="#optimagic-a-unified-interface-to-optimizers" title="Permalink to this headline">¬∂</a></h1>
<p>Optimagic allows users to experiment with any supported optimizer using a consistent interface similar to that of scipy‚Äôs. Simply change the algorithm, and optimagic handles the rest. Like,</p>
<section id="flexibility-at-its-core">
<h2>Flexibility at its core.<a class="headerlink" href="#flexibility-at-its-core" title="Permalink to this headline">¬∂</a></h2>
<p><a class="reference external" href="https://optimagic.readthedocs.io/en/latest/development/ep-01-pytrees.html">PyTrees</a> enable Optimagic to handle a wide variety of input formats, making it highly flexible.</p>
</section>
<section id="consistency-is-the-key">
<h2>Consistency is the key<a class="headerlink" href="#consistency-is-the-key" title="Permalink to this headline">¬∂</a></h2>
<p>Optimagic standardizes parameter names across optimizers. For example, all stopping criteria start with <code class="docutils literal notranslate"><span class="pre">stopping_maxiter</span></code> (maximum number of iterations), and all convergence criteria begin with <code class="docutils literal notranslate"><span class="pre">convergence_ftol_rel</span></code> (relative function tolerance).</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="code-contributions">
<h1>Code Contributions üíª<a class="headerlink" href="#code-contributions" title="Permalink to this headline">¬∂</a></h1>
<p>The primary objective was to add more optimizers to Optimagic, also some additional changes were done. These are detailed below.</p>
<section id="optimizers-from-nevergrad-merged">
<h2>Optimizers from Nevergrad <a class="reference external" href="https://github.com/optimagic-dev/optimagic/pull/591">(Merged)</a><a class="headerlink" href="#optimizers-from-nevergrad-merged" title="Permalink to this headline">¬∂</a></h2>
<p>This was a pretty big PR and I worked on this from Week 1 to Week 4.</p>
<section id="why-nevergrad">
<h3>Why Nevergrad?<a class="headerlink" href="#why-nevergrad" title="Permalink to this headline">¬∂</a></h3>
<p>Nevergrad offers a robust set of derivative-free optimization algorithms. Integrating these into Optimagic would allows users to leverage cutting-edge methods through a same API. In machine learning and AI, black-box functions‚Äîwhere only inputs and outputs are known, and the internal workings are non-differentiable and non-convex benefit greatly from derivative-free methods, which effectively explore the function landscape to find optima.</p>
<ul class="simple">
<li><p><strong>Covariance Matrix Adaptation Evolution Strategy (CMA-ES)</strong><br />
CMA-ES has many parameters, and I analyzed them to identify those most critical to its adaptation process.</p></li>
<li><p><strong>OnePlusOne Evolution Strategy</strong><br />
This is a simplified variant of CMA-ES where ((\mu, \lambda) = (1, 1)), meaning one parent generates one offspring per iteration.</p></li>
<li><p><strong>Random Search</strong><br />
A one-shot method for sampling the search space which serves as the baseline.</p></li>
<li><p><strong>Sampling Search</strong><br />
Improved over Random Search.</p></li>
<li><p><strong>Differential Evolution</strong><br />
A population-based method for global optimization.</p></li>
<li><p><strong>Bayesian Optimization</strong><br />
A wrapper around the <code class="docutils literal notranslate"><span class="pre">bayes_optim</span></code> package.</p></li>
<li><p><strong>Estimation of Distribution Algorithm (EDA)</strong><br />
A probabilistic method for adaptive sampling.</p></li>
<li><p><strong>Test-Based Population Sampling Adaptation</strong><br />
An algorithm for continuous noisy optimization.</p></li>
<li><p><strong>Estimation of Multivariate Normal Algorithm (EMNA)</strong><br />
A probabilistic method for adaptive sampling. When papers were unavailable, I delved deeply into the code to understand its mechanics.</p></li>
<li><p><strong>NGOPT Optimizers</strong><br />
NGOpt (Nevergrad Optimizer) is the optimizer selection wizard of Nevergrad. Nevergrad‚Äôs meta-optimizers dynamically switch between algorithms based on the function landscape and optimization history.</p></li>
<li><p><strong>META Optimizers</strong><br />
These combine derivative-free global optimizers with derivative-based local optimizers to refine solutions.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We skipped SPSA from Nevergrad due to failing tests and lack of tunable parameters. I also excluded optimizers like ConfSplit, as their functionality can be achieved through multiple optimization runs.</p>
</div>
</section>
<section id="example-usage">
<h3>Example usage<a class="headerlink" href="#example-usage" title="Permalink to this headline">¬∂</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="kn">import</span><span class="w"> </span><span class="nn">optimagic</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">om</span>
</span><span data-line="2"><span class="n">om</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
</span><span data-line="3">    <span class="n">fun</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="nd">@x</span><span class="p">,</span>
</span><span data-line="4">    <span class="n">params</span><span class="o">=</span><span class="n">om</span><span class="o">.</span><span class="n">Bounds</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="p">),</span> <span class="n">upper</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">)),</span>
</span><span data-line="5">    <span class="n">algorithm</span><span class="o">=</span><span class="n">om</span><span class="o">.</span><span class="n">algos</span><span class="o">.</span><span class="n">nevergrad_meta</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;BFGSCMAPlus&quot;</span><span class="p">)</span>
</span><span data-line="6"><span class="p">)</span>
</span></pre></div>
</div>
</section>
</section>
<section id="adding-needs-bounds-and-supports-infinite-bounds-fields-in-the-algoinfo-merged">
<h2>Adding <code class="docutils literal notranslate"><span class="pre">needs_bounds</span></code> and <code class="docutils literal notranslate"><span class="pre">supports_infinite_bounds</span></code> fields in the AlgoInfo <a class="reference external" href="https://github.com/optimagic-dev/optimagic/pull/610">(Merged)</a><a class="headerlink" href="#adding-needs-bounds-and-supports-infinite-bounds-fields-in-the-algoinfo-merged" title="Permalink to this headline">¬∂</a></h2>
<p>During Week 5 and Week 6 I worked on this PR.</p>
<p>While global optimizers typically require bounds, optimizers from Nevergrad can operate without bounds by which in case sample from a normal distribution with given standard deviation. This was a open issue . Local algorithms often run unbounded, while global ones need bounds.I researched which algorithms could run without bounds and which supported infinite bounds. As a result, we added two new fields to the AlgoInfo class: <code class="docutils literal notranslate"><span class="pre">needs_bounds</span></code> and <code class="docutils literal notranslate"><span class="pre">supports_infinite_bounds</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="kn">from</span><span class="w"> </span><span class="nn">optimagic.algorithms</span><span class="w"> </span><span class="kn">import</span> <span class="n">AVAILABLE_ALGORITHMS</span>
</span><span data-line="2">
</span><span data-line="3"><span class="n">algos_with_bounds_support</span> <span class="o">=</span> <span class="p">[</span>
</span><span data-line="4">    <span class="n">algo</span>
</span><span data-line="5">    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">algo</span> <span class="ow">in</span> <span class="n">AVAILABLE_ALGORITHMS</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
</span><span data-line="6">    <span class="k">if</span> <span class="n">algo</span><span class="o">.</span><span class="n">algo_info</span><span class="o">.</span><span class="n">supports_bounds</span>
</span><span data-line="7"><span class="p">]</span>
</span><span data-line="8"><span class="n">my_selection</span> <span class="o">=</span> <span class="p">[</span>
</span><span data-line="9">    <span class="n">algo</span> <span class="k">for</span> <span class="n">algo</span> <span class="ow">in</span> <span class="n">algos_with_bounds_support</span> <span class="k">if</span> <span class="n">algo</span><span class="o">.</span><span class="n">algo_info</span><span class="o">.</span><span class="n">needs_bounds</span>
</span><span data-line="10"><span class="p">]</span>
</span></pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">my_selection2</span> <span class="o">=</span> <span class="p">[</span>
</span><span data-line="2">    <span class="n">algo</span>
</span><span data-line="3">    <span class="k">for</span> <span class="n">algo</span> <span class="ow">in</span> <span class="n">algos_with_bounds_support</span>
</span><span data-line="4">    <span class="k">if</span> <span class="n">algo</span><span class="o">.</span><span class="n">algo_info</span><span class="o">.</span><span class="n">supports_infinite_bounds</span>
</span><span data-line="5"><span class="p">]</span>
</span></pre></div>
</div>
</section>
<section id="migrate-nevergrad-optimizers-to-new-documentation-style-open">
<h2>Migrate Nevergrad optimizers to new documentation style <a class="reference external" href="https://github.com/optimagic-dev/optimagic/pull/632">(Open)</a><a class="headerlink" href="#migrate-nevergrad-optimizers-to-new-documentation-style-open" title="Permalink to this headline">¬∂</a></h2>
<p>Previously, documentation was stored in <code class="docutils literal notranslate"><span class="pre">algorithms.md</span></code> and optimizers in <code class="docutils literal notranslate"><span class="pre">optimizers.py</span></code>. I migrated Nevergrad optimizers to Optimagic‚Äôs new documentation style, embedding details in class docstrings and parameter docstrings to follow the new style. With this, I also cleaned up any remaining work and linked issues.</p>
</section>
<section id="wrap-local-optimizers-from-gradient-free-optimizers-open">
<h2>Wrap Local Optimizers from Gradient-Free Optimizers <a class="reference external" href="https://github.com/optimagic-dev/optimagic/pull/624">(Open)</a><a class="headerlink" href="#wrap-local-optimizers-from-gradient-free-optimizers-open" title="Permalink to this headline">¬∂</a></h2>
<p>After discussing with my mentor, we decided to wrap optimizers from this library and worked on this and following PR during Week 7 to Week 11.</p>
<p>These optimizers work on a discrete search space, requiring bounds to be translated into a grid, used helper functions for this process. I also added documentation and tests to ensure reliability.</p>
<p>A challenge was that these global optimizers struggled to pass tests due to low accuracy and search space limitations.</p>
<p>These are all local algorithms:</p>
<ul class="simple">
<li><p><strong>Hill Climbing</strong><br />
A local optimization method that iteratively moves to better neighboring solutions.</p></li>
<li><p><strong>Stochastic Hill Climbing</strong><br />
A variant of hill climbing that incorporates randomness to escape local optima.</p></li>
<li><p><strong>Simulated Annealing</strong><br />
A probabilistic technique that mimics the cooling process to find global optima, though used here for local optimization.</p></li>
<li><p><strong>Repulsing Hill Climbing</strong><br />
A variation of hill climbing that avoids revisiting solutions.</p></li>
<li><p><strong>Downhill Simplex Optimization</strong><br />
A derivative-free method using a simplex to navigate the search space.</p></li>
<li><p><strong>Powell‚Äôs Method</strong><br />
A local optimization technique using conjugate directions.</p></li>
</ul>
<p>I am very thankful to the developer of Gradient-Free Optimizers for patiently helping me understand the workings and clarify any doubts which I had.
<a class="reference external" href="https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/84">No improvement even after many iterations with some algorithms bug Something isn‚Äôt working</a></p>
</section>
<section id="wrap-population-based-optimizers-from-gradient-free-optimizers-open">
<h2>Wrap Population-Based Optimizers from Gradient-Free Optimizers <a class="reference external" href="https://github.com/optimagic-dev/optimagic/pull/636">(Open)</a><a class="headerlink" href="#wrap-population-based-optimizers-from-gradient-free-optimizers-open" title="Permalink to this headline">¬∂</a></h2>
<p>Thanks to the exposed converter, population-based algorithms can now be initialized with a initial population.
The following algorithms are now available in optimagic.</p>
<ul class="simple">
<li><p><strong>Particle Swarm Optimization</strong><br />
This is a population-based method inspired by the social behavior of flocks.</p></li>
<li><p><strong>Spiral Optimization</strong><br />
A global method that searches the space in a spiral pattern.</p></li>
<li><p><strong>Genetic Algorithm</strong><br />
A population-based method using principles of natural selection.</p></li>
<li><p><strong>Evolution Strategy</strong><br />
A population-based method c that evolves a population of solutions.</p></li>
<li><p><strong>Differential Evolution</strong><br />
A population-based method for global optimization, also implemented in Nevergrad.</p></li>
</ul>
<section id="rework-test-many-algorithms">
<h3>Rework <code class="docutils literal notranslate"><span class="pre">test_many_algorithms</span></code><a class="headerlink" href="#rework-test-many-algorithms" title="Permalink to this headline">¬∂</a></h3>
<p>We refactored the test suite to include dynamic tests for <code class="docutils literal notranslate"><span class="pre">needs_bounds</span></code> and <code class="docutils literal notranslate"><span class="pre">supports_infinite_bounds</span></code>. We also introduced a dictionary to specify precision requirements for certain algorithms.</p>
</section>
<section id="new-example-in-class-sphereexampleinternaloptimizationproblemwithconverter">
<h3>New Example in class SphereExampleInternalOptimizationProblemWithConverter<a class="headerlink" href="#new-example-in-class-sphereexampleinternaloptimizationproblemwithconverter" title="Permalink to this headline">¬∂</a></h3>
<p>PyTrees enable Optimagic to handle diverse inputs. Previously, a test object for PyTrees was missing, so I added an example in <code class="docutils literal notranslate"><span class="pre">internal_optimization_problem.py</span></code> to support testing with dictionary inputs via converter functions.</p>
<p>Example snippet</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span data-line="2"><span class="kn">from</span><span class="w"> </span><span class="nn">optimagic.optimization.internal_optimization_problem</span><span class="w"> </span><span class="kn">import</span> <span class="n">SphereExampleInternalOptimizationProblemWithConverter</span>
</span><span data-line="3"><span class="kn">from</span><span class="w"> </span><span class="nn">optimagic.typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">AggregationLevel</span>
</span><span data-line="4"><span class="n">problem</span> <span class="o">=</span> <span class="n">SphereExampleInternalOptimizationProblemWithConverter</span><span class="p">(</span><span class="n">solver_type</span><span class="o">=</span><span class="n">AggregationLevel</span><span class="o">.</span><span class="n">LEAST_SQUARES</span><span class="p">)</span>
</span><span data-line="5"><span class="n">problem</span><span class="o">.</span><span class="n">converter</span><span class="o">.</span><span class="n">params_to_internal</span><span class="p">({</span><span class="s2">&quot;x0&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;x1&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">})</span>
</span><span data-line="6"><span class="n">problem</span><span class="o">.</span><span class="n">converter</span><span class="o">.</span><span class="n">derivative_to_internal</span><span class="p">(</span>
</span><span data-line="7">    <span class="p">{</span>
</span><span data-line="8">    <span class="s2">&quot;x0&quot;</span><span class="p">:{</span>
</span><span data-line="9">         <span class="s2">&quot;x0&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="10">         <span class="s2">&quot;x1&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span>
</span><span data-line="11">        <span class="p">},</span>
</span><span data-line="12">   <span class="s2">&quot;x1&quot;</span><span class="p">:{</span>
</span><span data-line="13">       <span class="s2">&quot;x0&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="14">       <span class="s2">&quot;x1&quot;</span><span class="p">:</span><span class="mi">3</span>
</span><span data-line="15">       <span class="p">}</span>
</span><span data-line="16">    <span class="p">},</span>
</span><span data-line="17">    <span class="p">[</span><span class="mi">2</span><span class="p">,])</span>
</span></pre></div>
</div>
</section>
</section>
<section id="add-l-bfgs-optimizer-from-pyensmallen-open">
<h2>Add L-BFGS optimizer from pyensmallen <a class="reference external" href="https://github.com/optimagic-dev/optimagic/pull/566">(Open)</a><a class="headerlink" href="#add-l-bfgs-optimizer-from-pyensmallen-open" title="Permalink to this headline">¬∂</a></h2>
<p>ensmallen is a fast C++ library for efficient objective functions. This integration is pending due to delays in the pyensmallen repository. The challenge was an inactive repository maintainer, which hindered communication. Once a dependent PR is merged, this will be completed.
<a class="reference external" href="https://github.com/apoorvalal/pyensmallen/pull/17">Cleaned Report callback PR</a></p>
</section>
<section id="issues-raised-by-me">
<h2>Issues raised by me:<a class="headerlink" href="#issues-raised-by-me" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/optimagic-dev/optimagic/issues/606">Improve handling of internal nonlinear_constraints</a></p></li>
<li><p><a class="reference external" href="https://github.com/optimagic-dev/optimagic/issues/628">Improper docs build of How to guide - How to specify params bug</a></p></li>
<li><p><a class="reference external" href="https://github.com/facebookresearch/nevergrad/issues/1701">bayesian_optimization</a></p></li>
<li><p><a class="reference external" href="https://github.com/facebookresearch/nevergrad/issues/1697">Unable to retrieve loss for Parametrized CMA</a></p></li>
</ul>
</section>
<section id="what-does-this-mean">
<h2>What does this mean<a class="headerlink" href="#what-does-this-mean" title="Permalink to this headline">¬∂</a></h2>
<p>By integrating these optimizers, Optimagic now offers a more comprehensive toolkit for tackling optimization challenges.</p>
</section>
<section id="future-work">
<h2>Future Work<a class="headerlink" href="#future-work" title="Permalink to this headline">¬∂</a></h2>
<section id="wrap-grid-search-and-smbo-based-optimizers-from-gradient-free-optimizers">
<h3>Wrap Grid Search and SMBO-Based Optimizers from Gradient-Free Optimizers<a class="headerlink" href="#wrap-grid-search-and-smbo-based-optimizers-from-gradient-free-optimizers" title="Permalink to this headline">¬∂</a></h3>
<p>I plan to wrap Grid Search and other optimizers, including:</p>
<ul class="simple">
<li><p>Bayesian Optimization</p></li>
<li><p>Tree-Structured Parzen Estimators</p></li>
<li><p>Forest Optimization</p></li>
</ul>
</section>
<section id="maintenance">
<h3>Maintenance üõ†Ô∏è<a class="headerlink" href="#maintenance" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p>Support for nonlinear constraints with optimizers from Nevergrad</p></li>
<li><p>Document particular portfolio and meta optimizers in <code class="docutils literal notranslate"><span class="pre">nevergrad_meta</span></code> and <code class="docutils literal notranslate"><span class="pre">nevergrad_ngopt</span></code> which are not documented sufficiently in
the nevergrad documentation but which can be sourced through other papers.</p></li>
<li><p>Support for nonlinear constraints with optimizers from Gradient-Free Optimizers</p></li>
</ul>
</section>
</section>
<section id="acknowledgements">
<h2>Acknowledgements<a class="headerlink" href="#acknowledgements" title="Permalink to this headline">¬∂</a></h2>
<p>I am deeply grateful to the following individuals and institutions for their support:</p>
<p>Firstly, I thank my GSoC mentors <a class="reference external" href="https://github.com/janosg">Janos Gabler</a> and <a class="reference external" href="https://github.com/timmens">Tim Mensinger</a> for their warm welcome, openness to new ideas, and fostering a constructive and engaging discussion environment.</p>
<p>I also appreciate the contributions of community members who provided valuable feedback and comments on my pull requests.</p>
<p>Finally, I express my gratitude to the Google Summer of Code program for providing the opportunity and financial support, enabling me to pursue my academic interests and enhance my technical skills with minimal constraints.</p>
</section>
</section>

        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, gauravmanmode</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
      <script src="_static/jquery.js"></script>
      <script src="_static/underscore.js"></script>
      <script src="_static/doctools.js"></script>
      <script src="_static/shibuya.js"></script></body>
</html>